{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT VISION API TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scraping our dog images, it's time to evaluate the performance of OpenAI's Vision API. While our ultimate goal is to develop our own breed classifier using TensorFlow and neural networks, for our initial tests, we've opted to utilize OpenAI services. Our first step is to use Vision-GPT to identify potential dog breeds within images. However, we've encountered an issue with Vision-GPT's ability to provide concise responses. To address this, we're considering alternatives such as GPT-4 and simpler models like GPT-3.5, as they weren't sufficient during our preliminary trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re \n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to put the Vision API to the test using the images from our dataset. To achieve this, we'll open our \"image-details.csv\" file to iterate through each image name. We'll then create two new columns: one to store the response from the OpenAI API and another to save the tokens used. Afterwards, we'll explore various methods and parameters to determine the most cost-effective alternative for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open csv with image data\n",
    "df = pd.read_csv('./output/raw/images/image_data.csv')\n",
    "# Add columns for vision response and tokens\n",
    "df['Vision Response'] = None\n",
    "df['Vision Tokens'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api key for OpenAI\n",
    "api_key  = 'sk-'\n",
    "# Set up OpenAI client\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With reference to the OpenAI documentation (https://platform.openai.com/docs/guides/vision), we developed a function to iterate through the DataFrame's image names. This function utilizes the OpenAI Vision API to generate responses, which are then saved in a new column along with the tokens used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_request(df, api_key, type):\n",
    "  '''\n",
    "  df: pandas dataframe\n",
    "  api_key: OpenAI api key\n",
    "  type: low, auto or high quality\n",
    "\n",
    "  This function takes a dataframe with a column 'File Name' and sends a request to OpenAI's vision model.\n",
    "  The response is then added to the dataframe in a new column 'Vision Response'.\n",
    "\n",
    "  '''\n",
    "\n",
    "  # Function to encode image to base64\n",
    "  def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "      return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Loop through the dataframe and send a request to OpenAI for each image\n",
    "  for i, file_name in enumerate(df['File Name']):\n",
    "    # Path to image\n",
    "    image_path = './imgs/' + file_name\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path)\n",
    "    # headers for the request\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    # payload for the request\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"Give me three possible breeds the dog is its okeay if you dont know the breed.\"\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                \"detail\": type\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 3000\n",
    "    }\n",
    "    # Send the request\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    # Get the response\n",
    "    data = response.json()\n",
    "    # Get the tokens used\n",
    "    tokens = data['usage']\n",
    "    # Add the response and tokens to the dataframe\n",
    "    df.at[i, 'Vision Tokens'] = tokens\n",
    "    content = data['choices'][0]['message']['content']\n",
    "    df.at[i, 'Vision Response'] = content\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the large number of images (over 500), we chose to split the CSV into smaller groups, each containing approximately 6 images. By doing so, we mitigate the risk of losing substantial progress and incurring unnecessary costs due to the tokens used in case of any unforeseen issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_vision(df, type):\n",
    "    '''\n",
    "    df: pandas dataframe\n",
    "    type: low, auto or high quality\n",
    "\n",
    "    This function takes a dataframe with a column 'File Name' and sends a request to OpenAI's vision model.\n",
    "    The response is then added to the dataframe in a new column 'Vision Response'.\n",
    "    '''\n",
    "    # Split dataframe into near equal groups\n",
    "    group_size = len(df) // 100 \n",
    "    # Split dataframe into groups\n",
    "    groups = [df.iloc[i:i+group_size].reset_index(drop=True) for i in range(0, len(df), group_size)]\n",
    "    # Loop through groups and send requests\n",
    "    for i, group in enumerate(groups):\n",
    "        # Send request\n",
    "        processed_group = vision_request(group, api_key)\n",
    "        # Save group to csv\n",
    "        processed_group.to_csv(f\"./output/raw/groups/{type}/group_{i}.csv\", index=False)\n",
    "        # Sleep for 10 second to avoid rate limits\n",
    "        time.sleep(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The concatenate_groups function merges multiple CSV files of the same type into a single file. It reads the CSV files from the specified directory, concatenates them into a single DataFrame, and then saves the merged DataFrame to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatanate_groups(type, num_groups):\n",
    "    '''\n",
    "    type: low, auto or high quality\n",
    "    num_groups: number of groups to concatanate\n",
    "\n",
    "    This function concatanates the groups into one dataframe and saves it as a csv file.\n",
    "    '''\n",
    "    # Read in the groups and add them to a list\n",
    "    dfs = [pd.read_csv(f\"./output/raw/groups/{type}/group_{i}.csv\") for i in range(0,num_groups)]\n",
    "    # Concatanate the groups\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    # Save the dataframe as a csv\n",
    "    df.to_csv(f'./output/raw/vision/vision_{type}csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Request Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial tests of the Vision API revealed its inability to consistently provide concise answers. Often, it needed to clarify that its responses might not be entirely accurate. Typically, the answers followed this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the image, the dog appears to be a Dachshund. This breed is characterized by its long body and short legs, along with a prominent snout. It's difficult to provide three possible breeds when the dog in the picture shows clear traits of a Dachshund, but for the sake of exploring possibilities:\n",
      "\n",
      "1. Dachshund\n",
      "2. Miniature Dachshund (if the dog is smaller in size)\n",
      "3. Dachshund mix (if it has mixed breed characteristics not visible in this image)\n",
      "\n",
      "It's worth noting that there can be some variations within the breed, such as differences in coat type (smooth, long-haired, or wire-haired) and size.\n",
      "\n",
      "I'm sorry, I can't provide assistance with that request.\n",
      "\n",
      "Given the physical characteristics visible in the image such as the round face, short snout, prominent eyes, and fluffy coat, the dog could possibly be one of the following three breeds or a mix involving one of these:\n",
      "\n",
      "1. Shih Tzu\n",
      "2. Lhasa Apso\n",
      "3. Pekingese\n",
      "\n",
      "These breeds share some similar physical attributes and are often mistaken for one another.\n"
     ]
    }
   ],
   "source": [
    "# Open csv with vision response\n",
    "df = pd.read_csv('./output/raw/vision/vision_low.csv')\n",
    "# Show a random response\n",
    "print(df['Vision Response'][np.random.randint(0, len(df))])\n",
    "print('')\n",
    "print(df['Vision Response'][np.random.randint(0, len(df))])\n",
    "print('')\n",
    "print(df['Vision Response'][np.random.randint(0, len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Although various methods exist to process this output, for this prototype, we'll analyze the text using the GPT-4 model with the following function. We decided to go with the GPT-4 function because older models prooved to not be enough in our initial testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dog_breeds(client, vision_response):\n",
    "    '''\n",
    "    client: OpenAI client\n",
    "    vision_response: string\n",
    "\n",
    "    This function takes a vision response and sends a request to OpenAI's chat model to get the dog breeds from the response. \n",
    "    '''\n",
    "\n",
    "    # Prompt for the chat model\n",
    "    prompt = 'give me the dog breeds in order of importance that appear in this text  separated by commas in case of an error write the word \"Error\"'\n",
    "    # Add the vision response to the prompt\n",
    "    message_content = str(prompt) + '\"' + str(vision_response) + '\"'\n",
    "    # Send the request to the chat model\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "    {\"role\": \"user\", \"content\": message_content},\n",
    "     ]\n",
    "    )\n",
    "    \n",
    "    # Get the breeds and tokens used\n",
    "    breeds = response.choices[0].message.content\n",
    "    total_tokens = response.usage.total_tokens\n",
    "    prompt_tokens = response.usage.prompt_tokens\n",
    "    completition_tokens = response.usage.completion_tokens\n",
    "    \n",
    "    return breeds, total_tokens, prompt_tokens, completition_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll apply the previously defined function to all the responses of GPT Vision in the DataFrame and save the tokens used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_breeds(df):\n",
    "    '''\n",
    "    df: pandas dataframe\n",
    "\n",
    "    This function cleans the breeds column in the dataframe.\n",
    "    '''\n",
    "    # Iterate through the dataframe and clean the breeds column\n",
    "    for i, group in enumerate(df['Vision Response']):\n",
    "        # Get the breeds\n",
    "        breeds, total_tokens, prompt_tokens, completition_tokens = get_dog_breeds(client, group)\n",
    "        # Add the breeds and tokens to the dataframe\n",
    "        df.at[i, 'Breeds'] = breeds\n",
    "        df.at[i, 'T Tokens Prompt'] = prompt_tokens\n",
    "        df.at[i, 'T Tokens Completition'] = completition_tokens\n",
    "        df.at[i, 'T Tokens Total'] = total_tokens\n",
    "        # Sleep for 2 seconds to avoid rate limits\n",
    "        time.sleep(2)\n",
    "\n",
    "    # Clean the breeds column\n",
    "    df = df.drop(columns=['Vision Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to save the vision tokens in the same manner as we saved the text tokens, utilizing three separate columns in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 111, 'completion_tokens': 52, 'total_tokens': 163}\n"
     ]
    }
   ],
   "source": [
    "print(df['Vision Tokens'][67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_tokens(df):\n",
    "    '''\n",
    "    df: pandas dataframe\n",
    "\n",
    "    This function extracts the vision tokens from the vision tokens column in the dataframe.\n",
    "    '''\n",
    "\n",
    "    # Add columns for vision tokens\n",
    "    df['V Tokens Prompt'] = None\n",
    "    df['V Tokens Completition'] = None\n",
    "    df['V Tokens Total'] = None\n",
    "    # Iterate through the dataframe and extract the vision tokens\n",
    "    for i, token_string in enumerate(df['Vision Tokens']):\n",
    "        # Define regular expression pattern to match token counts\n",
    "        pattern = r\"'(\\w+)': (\\d+)\"\n",
    "        # Find all matches using the pattern\n",
    "        matches = re.findall(pattern, token_string)\n",
    "        # Create a dictionary to store token counts\n",
    "        token_counts = {key: int(value) for key, value in matches}\n",
    "        # Add the token counts to the dataframe\n",
    "        df.at[i, 'V Tokens Prompt'] = token_counts['prompt_tokens']\n",
    "        df.at[i, 'V Tokens Completition'] = token_counts['completion_tokens']\n",
    "        df.at[i, 'V Tokens Total'] = token_counts['total_tokens']\n",
    "    # Drop the Vision Tokens column\n",
    "    df.drop(columns=['Vision Tokens'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>File Size (MB)</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Breeds</th>\n",
       "      <th>T Tokens Prompt</th>\n",
       "      <th>T Tokens Completition</th>\n",
       "      <th>T Tokens Total</th>\n",
       "      <th>V Tokens Prompt</th>\n",
       "      <th>V Tokens Completition</th>\n",
       "      <th>V Tokens Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Chompersthecorgi1.jpg</td>\n",
       "      <td>(1280, 1280)</td>\n",
       "      <td>0.107140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sh...</td>\n",
       "      <td>248</td>\n",
       "      <td>20</td>\n",
       "      <td>268</td>\n",
       "      <td>111</td>\n",
       "      <td>212</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Chompersthecorgi10.jpg</td>\n",
       "      <td>(2500, 1667)</td>\n",
       "      <td>0.584455</td>\n",
       "      <td>1.499700</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi</td>\n",
       "      <td>175</td>\n",
       "      <td>14</td>\n",
       "      <td>189</td>\n",
       "      <td>111</td>\n",
       "      <td>139</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Chompersthecorgi11.jpg</td>\n",
       "      <td>(259, 194)</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>1.335052</td>\n",
       "      <td>Error</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>111</td>\n",
       "      <td>21</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Chompersthecorgi12.jpg</td>\n",
       "      <td>(225, 225)</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Pembroke Welsh Corgi</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "      <td>111</td>\n",
       "      <td>71</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Chompersthecorgi13.jpg</td>\n",
       "      <td>(1200, 800)</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sw...</td>\n",
       "      <td>271</td>\n",
       "      <td>19</td>\n",
       "      <td>290</td>\n",
       "      <td>111</td>\n",
       "      <td>235</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File Name    Dimensions  File Size (MB)  Aspect Ratio  \\\n",
       "0   @Chompersthecorgi1.jpg  (1280, 1280)        0.107140      1.000000   \n",
       "1  @Chompersthecorgi10.jpg  (2500, 1667)        0.584455      1.499700   \n",
       "2  @Chompersthecorgi11.jpg    (259, 194)        0.004376      1.335052   \n",
       "3  @Chompersthecorgi12.jpg    (225, 225)        0.014020      1.000000   \n",
       "4  @Chompersthecorgi13.jpg   (1200, 800)        0.043723      1.500000   \n",
       "\n",
       "                                              Breeds T Tokens Prompt  \\\n",
       "0  Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sh...             248   \n",
       "1         Pembroke Welsh Corgi, Cardigan Welsh Corgi             175   \n",
       "2                                              Error              57   \n",
       "3                               Pembroke Welsh Corgi             107   \n",
       "4  Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sw...             271   \n",
       "\n",
       "  T Tokens Completition T Tokens Total V Tokens Prompt V Tokens Completition  \\\n",
       "0                    20            268             111                   212   \n",
       "1                    14            189             111                   139   \n",
       "2                     1             58             111                    21   \n",
       "3                     7            114             111                    71   \n",
       "4                    19            290             111                   235   \n",
       "\n",
       "  V Tokens Total  \n",
       "0            323  \n",
       "1            250  \n",
       "2            132  \n",
       "3            182  \n",
       "4            346  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_clean_breeds(df, type):\n",
    "    df.to_csv(f'./output/clean/breeds/breeds_{type}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Image Request"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
