{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT VISION API TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scraping our dog images, it's time to evaluate the performance of OpenAI's Vision API. While our ultimate goal is to develop our own breed classifier using TensorFlow and neural networks, for our initial tests, we've opted to utilize OpenAI services. Our first step is to use Vision-GPT to identify potential dog breeds within images. However, we've encountered an issue with Vision-GPT's ability to provide concise responses. To address this, we're considering alternatives such as GPT-4 and simpler models like GPT-3.5, as they weren't sufficient during our preliminary trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import re \n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to put the Vision API to the test using the images from our dataset. To achieve this, we'll open our \"image-details.csv\" file to iterate through each image name. We'll then create two new columns: one to store the response from the OpenAI API and another to save the tokens used. Afterwards, we'll explore various methods and parameters to determine the most cost-effective alternative for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open csv with image data\n",
    "df = pd.read_csv('./output/raw/images/image_data.csv')\n",
    "# Add columns for vision response and tokens\n",
    "df['Vision Response'] = None\n",
    "df['Vision Tokens'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api key for OpenAI\n",
    "api_key  = 'sk-'\n",
    "# Set up OpenAI client\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With reference to the OpenAI documentation (https://platform.openai.com/docs/guides/vision), we developed a function to iterate through the DataFrame's image names. This function utilizes the OpenAI Vision API to generate responses, which are then saved in a new column along with the tokens used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_request(df, api_key, type):\n",
    "  '''\n",
    "  df: pandas dataframe\n",
    "  api_key: OpenAI api key\n",
    "  type: low, auto or high quality\n",
    "\n",
    "  This function takes a dataframe with a column 'File Name' and sends a request to OpenAI's vision model.\n",
    "  The response is then added to the dataframe in a new column 'Vision Response'.\n",
    "\n",
    "  '''\n",
    "\n",
    "  # Function to encode image to base64\n",
    "  def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "      return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Loop through the dataframe and send a request to OpenAI for each image\n",
    "  for i, file_name in enumerate(df['File Name']):\n",
    "    # Path to image\n",
    "    image_path = './imgs/' + file_name\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path)\n",
    "    # headers for the request\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    # payload for the request\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"Give me three possible breeds the dog is its okeay if you dont know the breed.\"\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                \"detail\": type\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 3000\n",
    "    }\n",
    "    # Send the request\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    # Get the response\n",
    "    data = response.json()\n",
    "    # Get the tokens used\n",
    "    tokens = data['usage']\n",
    "    # Add the response and tokens to the dataframe\n",
    "    df.at[i, 'Vision Tokens'] = tokens\n",
    "    content = data['choices'][0]['message']['content']\n",
    "    df.at[i, 'Vision Response'] = content\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the large number of images (over 500), we chose to split the CSV into smaller groups, each containing approximately 6 images. By doing so, we mitigate the risk of losing substantial progress and incurring unnecessary costs due to the tokens used in case of any unforeseen issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_vision(df, type):\n",
    "    group_size = len(df) // 100  # Assuming you want approximately equal-sized groups\n",
    "    groups = [df.iloc[i:i+group_size].reset_index(drop=True) for i in range(0, len(df), group_size)]\n",
    "\n",
    "    for i, group in enumerate(groups[39:], start=39):\n",
    "        processed_group = vision_request(group, api_key)\n",
    "        processed_group.to_csv(f\"./output/raw/groups/{type}/group_{i}.csv\", index=False)\n",
    "        time.sleep(10)  # Sleep for 10 second to avoid rate limits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatanate_groups(type, num_groups):\n",
    "    dfs = [pd.read_csv(f\"./output/raw/groups/{type}/group_{i}.csv\") for i in range(0,num_groups)]\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    df.to_csv(f'./output/raw/vision/vision_{type}csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the image provided, it appears to be a fluffy dog with a long coat. Without seeing more of the dog's features, such as the face, it's a bit challenging to identify the breed with certainty. However, considering the coat type and assuming the dog is not a mixed breed or an atypical specimen, here are three possible breed guesses:\n",
      "\n",
      "1. Old English Sheepdog: Known for their shaggy coat, which is evident in the photo.\n",
      "2. Bearded Collie: They also have a long, flowing coat that could match what's seen in the image.\n",
      "3. Polish Lowland Sheepdog: Similar to the Old English Sheepdog with a somewhat less dense coat but still long and shaggy.\n",
      "\n",
      "Please note that these are just guesses, and without more information, it is difficult to determine the exact breed of the dog in the photo.\n"
     ]
    }
   ],
   "source": [
    "print(df['Vision Response'][474])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dog_breeds(client, vision_response):\n",
    "    prompt = 'give me the dog breeds in order of importance that appear in this text  separated by commas in case of an error write the word \"Error\"'\n",
    "    message_content = str(prompt) + '\"' + str(vision_response) + '\"'\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "    {\"role\": \"user\", \"content\": message_content},\n",
    "     ]\n",
    "    )\n",
    "    \n",
    "    breeds = response.choices[0].message.content\n",
    "    total_tokens = response.usage.total_tokens\n",
    "    prompt_tokens = response.usage.prompt_tokens\n",
    "    completition_tokens = response.usage.completion_tokens\n",
    "    \n",
    "    return breeds, total_tokens, prompt_tokens, completition_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, group in enumerate(df['Vision Response']):\n",
    "    breeds, total_tokens, prompt_tokens, completition_tokens = get_dog_breeds(client, group)\n",
    "    print(breeds, total_tokens, prompt_tokens, completition_tokens)\n",
    "    df.at[i, 'Breeds'] = breeds\n",
    "    df.at[i, 'T Tokens Prompt'] = prompt_tokens\n",
    "    df.at[i, 'T Tokens Completition'] = completition_tokens\n",
    "    df.at[i, 'T Tokens Total'] = total_tokens\n",
    "    time.sleep(2)\n",
    "\n",
    "df = df.drop(columns=['Vision Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>File Size (MB)</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Vision Tokens</th>\n",
       "      <th>Breeds</th>\n",
       "      <th>T Tokens Prompt</th>\n",
       "      <th>T Tokens Completition</th>\n",
       "      <th>T Tokens Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Chompersthecorgi1.jpg</td>\n",
       "      <td>(1280, 1280)</td>\n",
       "      <td>0.107140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'prompt_tokens': 111, 'completion_tokens': 21...</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sh...</td>\n",
       "      <td>248</td>\n",
       "      <td>20</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Chompersthecorgi10.jpg</td>\n",
       "      <td>(2500, 1667)</td>\n",
       "      <td>0.584455</td>\n",
       "      <td>1.499700</td>\n",
       "      <td>{'prompt_tokens': 111, 'completion_tokens': 13...</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi</td>\n",
       "      <td>175</td>\n",
       "      <td>14</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Chompersthecorgi11.jpg</td>\n",
       "      <td>(259, 194)</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>1.335052</td>\n",
       "      <td>{'prompt_tokens': 111, 'completion_tokens': 21...</td>\n",
       "      <td>Error</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Chompersthecorgi12.jpg</td>\n",
       "      <td>(225, 225)</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'prompt_tokens': 111, 'completion_tokens': 71...</td>\n",
       "      <td>Pembroke Welsh Corgi</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Chompersthecorgi13.jpg</td>\n",
       "      <td>(1200, 800)</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>{'prompt_tokens': 111, 'completion_tokens': 23...</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sw...</td>\n",
       "      <td>271</td>\n",
       "      <td>19</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File Name    Dimensions  File Size (MB)  Aspect Ratio  \\\n",
       "0   @Chompersthecorgi1.jpg  (1280, 1280)        0.107140      1.000000   \n",
       "1  @Chompersthecorgi10.jpg  (2500, 1667)        0.584455      1.499700   \n",
       "2  @Chompersthecorgi11.jpg    (259, 194)        0.004376      1.335052   \n",
       "3  @Chompersthecorgi12.jpg    (225, 225)        0.014020      1.000000   \n",
       "4  @Chompersthecorgi13.jpg   (1200, 800)        0.043723      1.500000   \n",
       "\n",
       "                                       Vision Tokens  \\\n",
       "0  {'prompt_tokens': 111, 'completion_tokens': 21...   \n",
       "1  {'prompt_tokens': 111, 'completion_tokens': 13...   \n",
       "2  {'prompt_tokens': 111, 'completion_tokens': 21...   \n",
       "3  {'prompt_tokens': 111, 'completion_tokens': 71...   \n",
       "4  {'prompt_tokens': 111, 'completion_tokens': 23...   \n",
       "\n",
       "                                              Breeds T Tokens Prompt  \\\n",
       "0  Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sh...             248   \n",
       "1         Pembroke Welsh Corgi, Cardigan Welsh Corgi             175   \n",
       "2                                              Error              57   \n",
       "3                               Pembroke Welsh Corgi             107   \n",
       "4  Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sw...             271   \n",
       "\n",
       "  T Tokens Completition T Tokens Total  \n",
       "0                    20            268  \n",
       "1                    14            189  \n",
       "2                     1             58  \n",
       "3                     7            114  \n",
       "4                    19            290  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 111, 'completion_tokens': 52, 'total_tokens': 163}\n"
     ]
    }
   ],
   "source": [
    "print(df['Vision Tokens'][67])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['V Tokens Prompt'] = None\n",
    "df['V Tokens Completition'] = None\n",
    "df['V Tokens Total'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token_string in enumerate(df['Vision Tokens']):\n",
    "    # Define regular expression pattern to match token counts\n",
    "    pattern = r\"'(\\w+)': (\\d+)\"\n",
    "\n",
    "    # Find all matches using the pattern\n",
    "    matches = re.findall(pattern, token_string)\n",
    "\n",
    "    # Create a dictionary to store token counts\n",
    "    token_counts = {key: int(value) for key, value in matches}\n",
    "\n",
    "    df.at[i, 'V Tokens Prompt'] = token_counts['prompt_tokens']\n",
    "    df.at[i, 'V Tokens Completition'] = token_counts['completion_tokens']\n",
    "    df.at[i, 'V Tokens Total'] = token_counts['total_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>File Size (MB)</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Breeds</th>\n",
       "      <th>T Tokens Prompt</th>\n",
       "      <th>T Tokens Completition</th>\n",
       "      <th>T Tokens Total</th>\n",
       "      <th>V Tokens Prompt</th>\n",
       "      <th>V Tokens Completition</th>\n",
       "      <th>V Tokens Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Chompersthecorgi1.jpg</td>\n",
       "      <td>(1280, 1280)</td>\n",
       "      <td>0.107140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sh...</td>\n",
       "      <td>248</td>\n",
       "      <td>20</td>\n",
       "      <td>268</td>\n",
       "      <td>111</td>\n",
       "      <td>212</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Chompersthecorgi10.jpg</td>\n",
       "      <td>(2500, 1667)</td>\n",
       "      <td>0.584455</td>\n",
       "      <td>1.499700</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi</td>\n",
       "      <td>175</td>\n",
       "      <td>14</td>\n",
       "      <td>189</td>\n",
       "      <td>111</td>\n",
       "      <td>139</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Chompersthecorgi11.jpg</td>\n",
       "      <td>(259, 194)</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>1.335052</td>\n",
       "      <td>Error</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>111</td>\n",
       "      <td>21</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Chompersthecorgi12.jpg</td>\n",
       "      <td>(225, 225)</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Pembroke Welsh Corgi</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "      <td>111</td>\n",
       "      <td>71</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Chompersthecorgi13.jpg</td>\n",
       "      <td>(1200, 800)</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sw...</td>\n",
       "      <td>271</td>\n",
       "      <td>19</td>\n",
       "      <td>290</td>\n",
       "      <td>111</td>\n",
       "      <td>235</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File Name    Dimensions  File Size (MB)  Aspect Ratio  \\\n",
       "0   @Chompersthecorgi1.jpg  (1280, 1280)        0.107140      1.000000   \n",
       "1  @Chompersthecorgi10.jpg  (2500, 1667)        0.584455      1.499700   \n",
       "2  @Chompersthecorgi11.jpg    (259, 194)        0.004376      1.335052   \n",
       "3  @Chompersthecorgi12.jpg    (225, 225)        0.014020      1.000000   \n",
       "4  @Chompersthecorgi13.jpg   (1200, 800)        0.043723      1.500000   \n",
       "\n",
       "                                              Breeds T Tokens Prompt  \\\n",
       "0  Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sh...             248   \n",
       "1         Pembroke Welsh Corgi, Cardigan Welsh Corgi             175   \n",
       "2                                              Error              57   \n",
       "3                               Pembroke Welsh Corgi             107   \n",
       "4  Pembroke Welsh Corgi, Cardigan Welsh Corgi, Sw...             271   \n",
       "\n",
       "  T Tokens Completition T Tokens Total V Tokens Prompt V Tokens Completition  \\\n",
       "0                    20            268             111                   212   \n",
       "1                    14            189             111                   139   \n",
       "2                     1             58             111                    21   \n",
       "3                     7            114             111                    71   \n",
       "4                    19            290             111                   235   \n",
       "\n",
       "  V Tokens Total  \n",
       "0            323  \n",
       "1            250  \n",
       "2            132  \n",
       "3            182  \n",
       "4            346  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Vision Tokens'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./output/clean/breeds/breeds_low.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error count for auto: 154\n",
      "Error count for low: 192\n"
     ]
    }
   ],
   "source": [
    "df_auto = pd.read_csv(\"output/clean/breeds/breeds_auto.csv\")\n",
    "df_low = pd.read_csv(\"output/clean/breeds/breeds_low.csv\")\n",
    "\n",
    "error_count_auto = (df_auto['Breeds'] == 'Error').sum()\n",
    "error_count_low = (df_low['Breeds'] == 'Error').sum()\n",
    "\n",
    "print(f\"Error count for auto: {error_count_auto}\")\n",
    "print(f\"Error count for low: {error_count_low}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_request_low(df, api_key):\n",
    "  def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "      return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "  for i, file_name in enumerate(df['File Name']):\n",
    "    image_path = './imgs/' + file_name\n",
    "\n",
    "\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"Give me three possible breeds the dog is its okeay if you dont know the breed.\"\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                \"detail\": \"low\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 3000\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    tokens = data['usage']\n",
    "    df.at[i, 'Vision Tokens'] = tokens\n",
    "    content = data['choices'][0]['message']['content']\n",
    "    df.at[i, 'Vision Response'] = content\n",
    "    print(content)\n",
    "\n",
    "  return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
