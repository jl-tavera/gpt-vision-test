{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping Dog Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "dogs_ig = [\n",
    "    '@itsdougthepug',\n",
    "    '@jiffpom',\n",
    "    '@marniethedog',\n",
    "    '@manny_the_frenchie',\n",
    "    '@crusoe_dachshund',\n",
    "    '@samsonthedood',\n",
    "    '@reagandoodle',\n",
    "    '@barkleysircharles',\n",
    "    '@popeyethefoodie',\n",
    "    '@izzythe.frenchie',\n",
    "    '@tunameltsmyheart',\n",
    "    '@toastmeetsworld',\n",
    "    '@mensweardog',\n",
    "    '@thiswildidea',\n",
    "    '@aspenthemountainpup',\n",
    "    '@dogwithsign',\n",
    "    '@goldenunicornrae',\n",
    "    '@jackson_the_dalmatian',\n",
    "    '@madmax_fluffyroad',\n",
    "    '@pavlovthecorgi',\n",
    "    '@tuckerbudzyn',\n",
    "    '@ppteamkler',\n",
    "    '@Theladyshortcake',\n",
    "    '@rocco_roni',\n",
    "    '@Chompersthecorgi',\n",
    "    '@siberianhusky_jax',\n",
    "    '@good.boy.ollie',\n",
    "    '@bluestaffyboulder',\n",
    "    '@lecorgi',\n",
    "    '@carterchowchow',\n",
    "    '@_gsdbear',\n",
    "    '@harlso',\n",
    "    '@KeyushTheStuntDog',\n",
    "    '@mayapolarbear',\n",
    "    '@marutaro',\n",
    "    '@henrythecoloradodog',\n",
    "    '@eddie_jackrussell',\n",
    "    '@tecuaniventura',\n",
    "    '@ppteamaria',\n",
    "    '@emmatheminifrenchie',\n",
    "    '@balooitsme',\n",
    "    '@pipperontour',\n",
    "    '@mayathedox',\n",
    "    '@hi_im_chewie',\n",
    "    '@frankietothemoon',\n",
    "    '@tinkerbellethedog',\n",
    "    '@loki_the_wolfdog',\n",
    "    '@dailydougie',\n",
    "    '@tikatheiggy',\n",
    "    '@norbertthedog'\n",
    "]\n",
    "\n",
    "def get_duplicates(lst):\n",
    "    return list(set([x for x in lst if lst.count(x) > 1]))\n",
    "\n",
    "print(get_duplicates(dogs_ig))\n",
    "print(len(dogs_ig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_images_from_google(wd, query, delay, max_images):\n",
    "\n",
    "\tdef scroll_down(wd):\n",
    "\t\twd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\t\ttime.sleep(delay)\n",
    "\n",
    "\tquery = query.replace('@', '')\n",
    "\t\n",
    "\turl = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
    "\twd.get(url)\n",
    "\n",
    "\timage_urls = set()\n",
    "\tskips = 0\n",
    "\n",
    "\twhile len(image_urls) + skips < max_images:\n",
    "\t\tscroll_down(wd)\n",
    "\n",
    "\t\tthumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "\n",
    "\t\tfor img in thumbnails[len(image_urls) + skips:max_images]:\n",
    "\t\t\ttry:\n",
    "\t\t\t\timg.click()\n",
    "\t\t\t\ttime.sleep(delay)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\timages = wd.find_elements(By.CLASS_NAME, \"sFlh5c\")\n",
    "\t\t\tfor image in images:\n",
    "\t\t\t\tif image.get_attribute('src') in image_urls:\n",
    "\t\t\t\t\tmax_images += 1\n",
    "\t\t\t\t\tskips += 1\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "\t\t\t\t\timage_urls.add(image.get_attribute('src'))\n",
    "\t\t\t\t\tprint(f\"Found {len(image_urls)}\")\n",
    "\n",
    "\treturn image_urls\n",
    "\n",
    "\n",
    "def download_image(download_path, url, file_name):\n",
    "\ttry:\n",
    "\t\timage_content = requests.get(url).content\n",
    "\t\timage_file = io.BytesIO(image_content)\n",
    "\t\timage = Image.open(image_file)\n",
    "\t\tfile_path = download_path + file_name\n",
    "\n",
    "\t\twith open(file_path, \"wb\") as f:\n",
    "\t\t\timage.save(f, \"JPEG\")\n",
    "\n",
    "\t\tprint(\"Success\")\n",
    "\texcept Exception as e:\n",
    "\t\tprint('FAILED -', e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_dogs_images(wd, dogs_ig, delay, max_images):\n",
    "\tfor dog in dogs_ig:\n",
    "\t\tquery = dog\n",
    "\t\turls = get_images_from_google(wd, query, delay, max_images)\n",
    "\n",
    "\t\tfor i, url in enumerate(urls):\n",
    "\t\t\tdownload_image(\"imgs/\", url, str(dog) + str(i) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@tinkerbellethedog', '@loki_the_wolfdog', '@dailydougie', '@tikatheiggy', '@norbertthedog']\n"
     ]
    }
   ],
   "source": [
    "print(dogs_ig[45:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder containing images\n",
    "folder_path = \"imgs/\"\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Initialize lists to store file names and dimensions\n",
    "file_names = []\n",
    "dimensions = []\n",
    "file_sizes = []\n",
    "aspect_ratios = []\n",
    "\n",
    "# Iterate through each file\n",
    "for file in files:\n",
    "    # Check if the file is an image\n",
    "    if file.endswith((\".png\", \".jpg\", \".jpeg\", \".gif\")):\n",
    "        # Get the full path of the image\n",
    "        image_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Open the image\n",
    "        with Image.open(image_path) as img:\n",
    "            # Get the dimensions\n",
    "            width, height = img.size\n",
    "            # Calculate aspect ratio\n",
    "            aspect_ratio = width / height\n",
    "            # Get file size\n",
    "            file_size = os.path.getsize(image_path) / (1024 * 1024)  # Convert to MB\n",
    "            # Append file name, dimensions, file size, and aspect ratio to the lists\n",
    "            file_names.append(file)\n",
    "            dimensions.append((width, height))\n",
    "            file_sizes.append(file_size)\n",
    "            aspect_ratios.append(aspect_ratio)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"File Name\": file_names, \n",
    "                   \"Dimensions\": dimensions, \n",
    "                   \"File Size (MB)\": file_sizes,\n",
    "                   \"Aspect Ratio\": aspect_ratios})\n",
    "df = df.sort_values(by=\"File Name\")\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv(\"image_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
