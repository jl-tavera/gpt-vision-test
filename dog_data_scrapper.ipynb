{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping Dog Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_ig = [\n",
    "    '@itsdougthepug',\n",
    "    # '@jiffpom',\n",
    "    # '@marniethedog',\n",
    "    # '@manny_the_frenchie'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1\n",
      "Found 2\n",
      "Found 3\n",
      "Found 4\n",
      "Found 5\n",
      "Found 6\n",
      "Success\n",
      "Success\n",
      "Success\n",
      "FAILED - cannot identify image file <_io.BytesIO object at 0x7f0184337180>\n",
      "Success\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "wd = webdriver.Chrome()\n",
    "\n",
    "def get_images_from_google(wd, query, delay, max_images):\n",
    "\tdef scroll_down(wd):\n",
    "\t\twd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\t\ttime.sleep(delay)\n",
    "\n",
    "\turl = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
    "\twd.get(url)\n",
    "\n",
    "\timage_urls = set()\n",
    "\tskips = 0\n",
    "\n",
    "\twhile len(image_urls) + skips < max_images:\n",
    "\t\tscroll_down(wd)\n",
    "\n",
    "\t\tthumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "\n",
    "\t\tfor img in thumbnails[len(image_urls) + skips:max_images]:\n",
    "\t\t\ttry:\n",
    "\t\t\t\timg.click()\n",
    "\t\t\t\ttime.sleep(delay)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\timages = wd.find_elements(By.CLASS_NAME, \"sFlh5c\")\n",
    "\t\t\tfor image in images:\n",
    "\t\t\t\tif image.get_attribute('src') in image_urls:\n",
    "\t\t\t\t\tmax_images += 1\n",
    "\t\t\t\t\tskips += 1\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "\t\t\t\t\timage_urls.add(image.get_attribute('src'))\n",
    "\t\t\t\t\tprint(f\"Found {len(image_urls)}\")\n",
    "\n",
    "\treturn image_urls\n",
    "\n",
    "\n",
    "def download_image(download_path, url, file_name):\n",
    "\ttry:\n",
    "\t\timage_content = requests.get(url).content\n",
    "\t\timage_file = io.BytesIO(image_content)\n",
    "\t\timage = Image.open(image_file)\n",
    "\t\tfile_path = download_path + file_name\n",
    "\n",
    "\t\twith open(file_path, \"wb\") as f:\n",
    "\t\t\timage.save(f, \"JPEG\")\n",
    "\n",
    "\t\tprint(\"Success\")\n",
    "\texcept Exception as e:\n",
    "\t\tprint('FAILED -', e)\n",
    "\n",
    "urls = get_images_from_google(wd,'@itsdougthepug', 4, 6)\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "\tdownload_image(\"imgs/\", url, str(i) + \".jpg\")\n",
    "\n",
    "wd.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
